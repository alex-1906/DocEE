{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af17607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "96ce3ec5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_file = \"data/WikiEvents/train.jsonl\"\n",
    "with open(input_file) as f:\n",
    "    lines = f.read().splitlines()\n",
    "    df_inter = pd.DataFrame(lines)\n",
    "    df_inter.columns = ['json_element']\n",
    "    df_inter['json_element'].apply(json.loads)\n",
    "    df_we = pd.json_normalize(df_inter['json_element'].apply(json.loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ac1bc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVertex(row):\n",
    "    vertexSet = []\n",
    "    for em in row.event_mentions:\n",
    "        t = em[\"trigger\"]\n",
    "        et = em['event_type']\n",
    "        vertexSet.append([{\n",
    "            'pos':[t[\"start\"],t[\"end\"]],\n",
    "            'type':et+\".\"+\"TRIGGER\",\n",
    "            'sent_id':t[\"sent_idx\"],\n",
    "            'name':t[\"text\"],\n",
    "            'id':em[\"id\"]\n",
    "        }])\n",
    "        for a in em[\"arguments\"]:\n",
    "            #find argument_entity by given id\n",
    "            arg_id = a['entity_id']\n",
    "\n",
    "            for ent in row.entity_mentions:\n",
    "                if(ent['id'] == arg_id):\n",
    "                    vertexSet.append([{\n",
    "                        'pos':[ent[\"start\"],ent[\"end\"]],\n",
    "                        'type':ent[\"entity_type\"],\n",
    "                        'sent_id':ent[\"sent_idx\"],\n",
    "                        'name':ent[\"text\"],\n",
    "                        'id':ent[\"id\"]\n",
    "                    }])       \n",
    "    return vertexSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56e34ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVertexAllEntities(row):\n",
    "    vertexSet = []\n",
    "    for em in row.event_mentions:\n",
    "        t = em[\"trigger\"]\n",
    "        et = em['event_type']\n",
    "        vertexSet.append([{\n",
    "            'pos':[t[\"start\"],t[\"end\"]],\n",
    "            'type':et+\".\"+\"TRIGGER\",\n",
    "            'sent_id':t[\"sent_idx\"],\n",
    "            'name':t[\"text\"],\n",
    "            'id':em[\"id\"]\n",
    "        }])\n",
    "    for ent in row.entity_mentions:\n",
    "        vertexSet.append([{\n",
    "            'pos':[ent[\"start\"],ent[\"end\"]],\n",
    "            'type':ent[\"entity_type\"],\n",
    "            'sent_id':ent[\"sent_idx\"],\n",
    "            'name':ent[\"text\"],\n",
    "            'id':ent[\"id\"]\n",
    "        }])       \n",
    "    return vertexSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "243093c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabels(row):\n",
    "    labels = []\n",
    "    for event in row.event_mentions:\n",
    "        for argument in event['arguments']:\n",
    "            head = -1\n",
    "            tail = -1\n",
    "            for idx, entity in enumerate(row.vertexSet):\n",
    "                #Achtung, sobald es mehrere mentions zu einer entity gibt klappt [0] nicht mehr!!!\n",
    "                if(entity[0]['id'] == event['id']):\n",
    "                    head = idx\n",
    "                if(entity[0]['id'] == argument['entity_id']):\n",
    "                    tail = idx\n",
    "            labels.append({\n",
    "                #r': event['event_type']+\".\"+argument['role'],\n",
    "                'r': argument['role'],\n",
    "                'h': head,\n",
    "                't': tail,\n",
    "                'evidence':[]\n",
    "            })\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b8e0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSents(row):\n",
    "    sents = []\n",
    "    for sent in row.sentences:\n",
    "        sent_tokens = []\n",
    "        for t in sent[0]:\n",
    "            sent_tokens.append(t[0])\n",
    "        sents.append(sent_tokens)\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95619643",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_we[\"vertexSet\"] = df_we.apply(getVertexAllEntities,axis=1)\n",
    "df_we[\"labels\"] = df_we.apply(getLabels,axis=1)\n",
    "df_we[\"title\"] = df_we[\"doc_id\"]\n",
    "df_we[\"sents\"] = df_we.apply(getSents,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8784f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_we.drop(columns=['text', 'sentences',\n",
    "                    'relation_mentions', 'event_mentions'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f13e345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_we.to_json(\"data/WikiEvents/train_docred_format_all.json\",orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac400458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "9cf5e99d7ac82fa170dee8f2d834d81363ffb9f2abaf66a9d44c538ec571c339"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
